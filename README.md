# Chat with your data using RAG and vector stores with LlamaIndex and GPT)
Hi!

This LlamaIndex RAG chatbot loads all your specified directory data into a vector store and then queries the vector store given the user's input.
Using the pprint_response function from LlamaIndex, the chatbot not only displays the answer but also the retrieved data source(s) and the confidence percentage.

The following libraries are needed:

- os (for setting up the OpenAI API-key)

- llama_index


As always, the code is thoroughly commented.

Have fun!
